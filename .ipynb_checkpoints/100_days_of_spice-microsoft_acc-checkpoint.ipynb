{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# install youtubedl library\n",
    "# sudo -H pip install --upgrade youtube-dl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## download youtube video"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# downloading all the videos from the playlist - mp4 & highest quality\n",
    "# latest: 39 videos from 1/23/17 to 4/3/17\n",
    "# https://www.youtube.com/playlist?list=PLRJNAhZxtqH_3Nl-7n1vhgTUHyFSuQ0nI\n",
    "\n",
    "# os.system(\"youtube-dl -f 'bestvideo[ext=mp4]/best[ext=mp4]/best' -citk https://www.youtube.com/playlist?list=PLRJNAhZxtqH_3Nl-7n1vhgTUHyFSuQ0nI\")\n",
    "\n",
    "\n",
    "# os.system(\"youtube-dl -f bestvideo+bestaudio https://www.youtube.com/watch?v=hTpoxrEbKFk&list=PLRJNAhZxtqH_3Nl-7n1vhgTUHyFSuQ0nI&index=39\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "## files to delet\n",
    "\n",
    "#President Trump Holds a Press Conference-Ct0H_ndjavM.mp4\n",
    "#President Trump and Prime Minister Trudeau-vqkb-sJ31S4.mp4\n",
    "#President Trump and PM May Joint Press Conference-8TYCHq9cAS8.mp4\n",
    "#Joint Statment by President Trump and Prime Minister Shinz≈ç Abe-ntlqA33SL-k.mp4\n",
    "#Joint Press Conference-IbpsmS2BTLo.mp4\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Extracting stills from videos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    "import math\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "cv2.__version__ # this will print the version of your opencv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# def extract_stills(videoFile, extraction_rate, output_address, output_name):\n",
    "#     \"\"\"This function takes the location of a video and extract stills based on the user desired rate.\n",
    "#     It requires importing cv2 and math libraries.\n",
    "    \n",
    "#     parameters\n",
    "#     video: locaiton of the video - string\n",
    "#     extraction_rate: rate of extracting stills in seconds - int\"\"\"\n",
    "    \n",
    "#     # setting up the file\n",
    "#     vidcap = cv2.VideoCapture(videoFile)\n",
    "    \n",
    "#     # setting up parameters\n",
    "#     seconds = 1000\n",
    "#     fps = int(round(vidcap.get(cv2.CAP_PROP_FPS))) # Gets the frames per second\n",
    "#     total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "#     duration = (round(total_frames/fps) -1)*1000\n",
    "    \n",
    "#     location = output_address + output_name + '%d.jpg'\n",
    "#     #extracting every 'extraction_rate' of the video\n",
    "#     for i in range(0, duration, extraction_rate * 1000):\n",
    "#         vidcap.set(cv2.CAP_PROP_POS_MSEC,i)\n",
    "#         success,image = vidcap.read()\n",
    "#         j = i/1000\n",
    "# #         return cv2.imwrite(location % j, image)     # save frame as JPEG file\n",
    "\n",
    "\n",
    "# # import cv2\n",
    "# # import os\n",
    "\n",
    "# # def video_to_frames(video, path_output_dir):\n",
    "# #     # extract frames from a video and save to directory as 'x.png' where \n",
    "# #     # x is the frame index\n",
    "# #     vidcap = cv2.VideoCapture(video)\n",
    "# #     count = 0\n",
    "# #     while vidcap.isOpened():\n",
    "# #         success, image = vidcap.read()\n",
    "# #         if success:\n",
    "# #             cv2.imwrite(os.path.join(path_output_dir, '%d.png') % count, image)\n",
    "# #             count += 1\n",
    "# #         else:\n",
    "# #             break\n",
    "# #     cv2.destroyAllWindows()\n",
    "# #     vidcap.release()\n",
    "\n",
    "# # video_to_frames('../somepath/myvid.mp4', '../somepath/out')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# # fourcc = cv2.VideoWriter_fourcc(*'H264')\n",
    "\n",
    "# # setting up the file\n",
    "# videoFile = '/Users/Amiros/GitHub/100_days_of_spice/3_31_17 - White House Press Briefing-Nr8Mu0-vPsQ.mp4'\n",
    "# vidcap = cv2.VideoCapture(videoFile)\n",
    "# success,image = vidcap.read()\n",
    "\n",
    "# # setting up parameters\n",
    "# seconds = 1000\n",
    "# fps = int(round(vidcap.get(cv2.CAP_PROP_FPS))) # Gets the frames per second\n",
    "# total_frames = int(vidcap.get(cv2.CAP_PROP_FRAME_COUNT))\n",
    "# duration = (round(total_frames/fps) -1)*1000\n",
    "\n",
    "# #extracting every 'second' of the video\n",
    "# for i in range(0, duration, seconds):\n",
    "#     vidcap.set(cv2.CAP_PROP_POS_MSEC,i)\n",
    "#     success,image = vidcap.read()\n",
    "#     j = i/1000\n",
    "#     cv2.imwrite(\"/Users/Amiros/GitHub/100_days_of_spice/images/4_3_17/4_3_17__%d.jpg\" % j, image)     # save frame as JPEG file"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Detecting Sean's face"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# from cognitive_face import face as CF\n",
    "# from urllib3 import util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# KEY = 'e3b77a2e317244f2a7198e9387190a64'\n",
    "# CF.Key.set(KEY)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# img_url = 'http://i2.cdn.cnn.com/cnnnext/dam/assets/170121181022-sean-spicer-donald-trump-inauguration-crowd-bts-00002515-large-169.jpg'\n",
    "# result = CF.detect(img_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CF.detect('https://upload.wikimedia.org/wikipedia/commons/3/3f/Press_secretary_Sean_Spicer.jpg')\n",
    "# # CF.detect('https://img.washingtonpost.com/wp-apps/imrs.php?src=https://img.washingtonpost.com/rf/image_960w/2010-2019/WashingtonPost/2017/01/25/Production/Daily/A-Section/Images/AFP_KO6YL.jpg&w=480')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# face_ids = ['e13dd2b8-c9a4-4035-86a8-6b37ac6ce77b', '2850cf17-4ea9-4285-86bb-d29c703338f1', '92f34cee-7038-476a-827c-b6f1e31de989']\n",
    "\n",
    "# CF.group(face_ids)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# CF.find_similars(help)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": false
   },
   "source": [
    "# Detecting emotions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Line magic function `%install_ext` not found.\n"
     ]
    }
   ],
   "source": [
    "import http.client, urllib, base64, requests\n",
    "import cognitive_face as CF \n",
    "from cognitive_face import util\n",
    "import time\n",
    "import os\n",
    "\n",
    "%install_ext https://raw.github.com/cpcloud/ipython-autotime/master/autotime.py\n",
    "%load_ext autotime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 4.22 ms\n"
     ]
    }
   ],
   "source": [
    "#Emotion Analysis parameters\n",
    "_url = 'https://api.projectoxford.ai/emotion/v1.0/recognize'\n",
    "_key = 'ead17ccf578a40b88f2bb425d11d4a66'  ######### Here you have to paste your primary key for EMOTION API\n",
    "_maxNumRetries = 5\n",
    "\n",
    "#Face detection parametrs\n",
    "CF.Key.set('d78211e12bba41a991382ade5d68745b') ######### set the key for FACE API "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 58.6 ms\n"
     ]
    }
   ],
   "source": [
    "# Image path\n",
    "urlImage= ''\n",
    "\n",
    "# Emtional Anlaysis function\n",
    "def processRequest( json, data, headers, params ):\n",
    "\n",
    "    retries = 0\n",
    "    result = None\n",
    "\n",
    "    while True:\n",
    "\n",
    "        response = requests.request( 'post', _url, json = json, data = data, headers = headers, params = params )\n",
    "\n",
    "        if response.status_code == 429: \n",
    "\n",
    "            print( \"Message: %s\" % ( response.json()['error']['message'] ) )\n",
    "\n",
    "            if retries <= _maxNumRetries: \n",
    "                time.sleep(1) \n",
    "                retries += 1\n",
    "                continue\n",
    "            else: \n",
    "                print( 'Error: failed after retrying!' )\n",
    "                break\n",
    "\n",
    "        elif response.status_code == 200 or response.status_code == 201:\n",
    "\n",
    "            if 'content-length' in response.headers and int(response.headers['content-length']) == 0: \n",
    "                result = None \n",
    "            elif 'content-type' in response.headers and isinstance(response.headers['content-type'], str): \n",
    "                if 'application/json' in response.headers['content-type'].lower(): \n",
    "                    result = response.json() if response.content else None \n",
    "                elif 'image' in response.headers['content-type'].lower(): \n",
    "                    result = response.content\n",
    "        else:\n",
    "            print( \"Error code: %d\" % ( response.status_code ) )\n",
    "            print( \"Message: %s\" % ( response.json()['error']['message'] ) )\n",
    "\n",
    "        break\n",
    "        \n",
    "    return result\n",
    "\n",
    "\n",
    "headers = dict()\n",
    "headers['Ocp-Apim-Subscription-Key'] = _key\n",
    "headers['Content-Type'] = 'application/json' \n",
    "\n",
    "json = { 'url': urlImage } \n",
    "data = None\n",
    "params = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 8.59 ms\n"
     ]
    }
   ],
   "source": [
    "# Face detect function\n",
    "def detect(image, face_id=True, landmarks=False, faceRectangle= False, attributes='gender'):\n",
    "    \n",
    "    url = 'detect'\n",
    "    headers, data, json = util.parse_image(image)\n",
    "    params = {\n",
    "        'returnFaceId': face_id and 'true',\n",
    "        'returnFaceLandmarks': landmarks and 'false',\n",
    "        'returnFaceAttributes': attributes,\n",
    "    }\n",
    "\n",
    "    return util.request('POST', url, headers=headers, params=params, json=json,\n",
    "                        data=data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 13.3 ms\n"
     ]
    }
   ],
   "source": [
    "# generate a fake url list to replicate S3 condition\n",
    "\n",
    "#### ATTNTION ----- change '4641' to match the number of last image+1 -----#######\n",
    "#### ATTNTION ----- change '1_23_17/1_23_17___%d.jpg' to match the path and names on your S3 bucket -----#######\n",
    "\n",
    "url_list = []\n",
    "for i in range(0,3446,1):\n",
    "    url = \"https://s3.amazonaws.com/100daysofspice/1_30_17/1_30_17___%d.jpg\" % i\n",
    "    url_list.append(url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error code: 503\n"
     ]
    }
   ],
   "source": [
    "# Face Detection & Emotion Analysis - UPDATED\n",
    "processed = {}\n",
    "face_detection = {}\n",
    "count = 0\n",
    "\n",
    "for single_image in url_list:\n",
    " \n",
    "    try:\n",
    "        face_detection[count] = detect(single_image)\n",
    "\n",
    "        json = { 'url': single_image } \n",
    "        processed[count] = processRequest(json, data, headers, params)  \n",
    "    except:\n",
    "        pass\n",
    "\n",
    "    try:\n",
    "        if face_detection[count][0]['faceRectangle'] == processed[count][0]['faceRectangle']:\n",
    "            face_detection[count][0].update(processed[count][0])\n",
    "            face_detection[count][1].update(processed[count][1])\n",
    "        if  face_detection[count][0]['faceRectangle'] == processed[count][1]['faceRectangle']:\n",
    "            face_detection[count][0].update(processed[count][1])\n",
    "            face_detection[count][1].update(processed[count][0])\n",
    "    except:\n",
    "        pass\n",
    "    \n",
    "    count += 1\n",
    "    \n",
    "    time.sleep(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# face_detection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Save the result as Json\n",
    "#### ATTNTION ----- update '1_23_17.json' to the name of your current folder #######\n",
    "\n",
    "import json\n",
    "with open('/Users/Amiros/GitHub/100_days_of_spice/json/1_30_17.json', 'w') as fp:\n",
    "    json.dump(face_detection, fp, sort_keys=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## json to csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import json\n",
    "import csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "This can probably be improved but serves the purpose of our analysis.\n",
    "I used Chris's schema so it will be useful for Quarz analysis.\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "EMOTIONS = [\n",
    "    'contempt',\n",
    "    'fear',\n",
    "    'sadness',\n",
    "    'disgust',\n",
    "    'anger',\n",
    "    'neutral',\n",
    "    'happiness',\n",
    "    'surprise',\n",
    "]\n",
    "\n",
    "\n",
    "CSV_COLUMNS = [\n",
    "    'url',\n",
    "    'frame_time',\n",
    "    'sean_happiness',\n",
    "    'sean_neutral',\n",
    "    'sean_anger',\n",
    "    'sean_contempt',\n",
    "    'sean_suprise',\n",
    "    'sean_sadness',\n",
    "    'sean_fear'\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "time: 25 ms\n"
     ]
    }
   ],
   "source": [
    "with open('/Users/Amiros/GitHub/100_days_of_spice/json/1_30_17.json') as data_file:    \n",
    "    json_data = json.load(data_file)\n",
    "    \n",
    "json_data = {int(k):v for k,v in json_data.items()} #converting keys to integer   \n",
    "frame_keys = sorted(json_data.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "csv_data = []\n",
    "   \n",
    "for key in frame_keys:\n",
    "    url = 'https://s3.amazonaws.com/100daysofspice/1_30_17/1_30_17___%d.jpg' % key\n",
    "    frame = json_data[key]\n",
    "        \n",
    "    row = {\n",
    "        #'frame': frame,\n",
    "        'url': url,\n",
    "        'frame_time': key,\n",
    "    }\n",
    "    \n",
    "    if len(frame) > 1:\n",
    "        for face in frame:\n",
    "            if face['faceAttributes']['gender'] == 'male':\n",
    "                prefix = 'sean_'\n",
    "                try:\n",
    "                    for emotion in EMOTIONS:\n",
    "                        row[prefix + emotion] = face['scores'][emotion]\n",
    "                except:\n",
    "                    pass\n",
    "                \n",
    "            row.pop(\"frame\", None)        \n",
    "      \n",
    "    elif len(frame) == 1:\n",
    "        for face in frame:\n",
    "            if face['faceAttributes']['gender'] == 'male':\n",
    "                prefix = 'sean_'\n",
    "                try:\n",
    "                    for emotion in EMOTIONS:\n",
    "                    #print(face['scores'][emotion])\n",
    "                        row[prefix + emotion] = face['scores'][emotion]\n",
    "                except:\n",
    "                    pass\n",
    "                ### assign emotions vale to each candidate and change the name to the respective one \n",
    "          \n",
    "        row.pop(\"frame\", None)        \n",
    "\n",
    "    csv_data.append(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df = pd.DataFrame(csv_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df.to_csv('csv/1_30_17-EMOTIONS.csv', sep=',', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
